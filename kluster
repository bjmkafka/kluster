#!/bin/bash
#
# kluster: generate docker compose files for custom Confluent Platform clusters
#

VERSION=6.1.2     # Docker image version to use defaulting to current
ZK=1              # Size of Zookeeper ensemble defaulting to standalone
AK=3              # Number of brokers per cluster
RACKS=0           # Round-robin brokers into racks if greater than 0
CLUSTERS=1        # Prefix Zookeeper paths with "/<num>" if greater than 0
JMX_PORTS=false   # Open ports for JMX on the first (or only) cluster
KAFKA_ONLY=false  # Exclude conponents other than Zookeeper and Kafka if true
KSQLDB=false      # Use ksqlDB conponents rather than KSQL
KSQLSRVRS=1       # Number of ksqlDB server instances
OBSERVE=null      # Include Control Center and "tools" containers
CMD=$(basename $0)

usage() {
    echo "
Usage:
  $CMD [-v <CP version>] [-b <brokers>] [-r <racks>] [-c <clusters>] [options]
  $CMD -h|--help

Options:
  -b <int>     Number of Apache Kafka brokers (default: 3, max: 9)
  -c <int>     Number of clusters
  -d           Use ksqlDB (.io) instead of CP KSQL
  -D <int>     Number of ksqlDB server instances (default: 1)
  -k           Use Apache Kafka components only
  -j           Open JMX ports (only for cluster 1)
  -o           Exclude observibility containers 'control-center' and 'tools'
  -O           Include 'control-center' and 'tools'
  -r <int>     Number of racks or availability zones (default: none)
  -v <version> Confluent Platform version (default: $VERSION)
  -z           Zookeeper 3 node ensemble (default: standalone)
  -Z <int>     Zookeeper ensemble with <int> nodes

Ports exposed on localhost:
  Zookeeper client  1000n
  Zookeeper admin   1008n
  Kafka client      10crb
  Zookeeper JMX     998n
  Kafka JMX         999n
  REST API ports    defaults + 10000

Mult-cluster Ports:
  Zookeeper are Control Center are shared between clusters
  Other components subtract 1000 for each cluster greater than 1

IDs:
  Zookeeper    n
  Broker ID  10n
  Rack ID    1n0
  Cluster ID n00" 1>&2;

    exit 1;
}

#
# Component functions
#

header () {
    cat << EOF
#
# Docker Compose file created from: "$CMD $ARGS"
#
version: '3.5'
services:

EOF
    if [ $OBSERVE = true ]; then
	cat <<EOF
  tools:
    image: cnfltraining/training-tools:latest
    hostname: tools
    container_name: tools
    volumes:
      - ${PWD}:/apps
    environment:
      CLASSPATH: "/usr/share/java/monitoring-interceptors/monitoring-interceptors-5.5.2.jar"
    working_dir: /apps
    networks:
      - confluent
    command: /bin/bash
    tty: true
EOF
    fi
}

zookeeper () {
    local i=$1
    local ZKNODES=$2

    echo "ZOOKEEPER $i zk$i" 1>&2
    cat << EOF

  zk${i}:
    image: confluentinc/cp-zookeeper:$VERSION
    container_name: zk${i}
    hostname: zk${i}
    # restart: always
    volumes:
      - zk${i}-data:/var/lib/zookeeper/data
      - zk${i}-log:/var/lib/zookeeper/log
    networks:
      - confluent
    ports:
      - 1000${i}:2181
      - 1008${i}:8080
EOF
    if [ $JMX_PORTS = true ]; then
	cat << EOF
      - 998${i}:998${i}
EOF
    fi
    cat << EOF
    environment:
      ZOOKEEPER_SERVER_ID: ${i}
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_INIT_LIMIT: 5
      ZOOKEEPER_SYNC_LIMIT: 2
EOF
    if [ -n "$ZKNODES" ]; then
	cat <<EOF
      ZOOKEEPER_SERVERS: $ZKNODES
EOF
    fi
    if [ $JMX_PORTS = true ]; then
	cat << EOF
      KAFKA_JMX_OPTS: '-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=zk${i} -Dcom.sun.management.jmxremote.rmi.port=998${i}'
      JMX_PORT: 998${i}
EOF
    fi
    if [ $VERINT -ge 540 ]; then
	cat <<EOF
      KAFKA_OPTS: '-Dzookeeper.4lw.commands.whitelist=*'
EOF
    fi
}

broker () {
    local CL=$1
    local RK=$2
    local ID=$3
    local JMX=$4

    local num=$CL$RK$ID
    local port=10$num

    CPIMAGE=cp-enterprise-kafka
    KCIMAGE=cp-kafka-connect
    if [ $VERINT -ge 530 ]; then
          CPIMAGE=cp-server
          KCIMAGE=cp-server-connect
    fi

    cat <<EOF

  kafka${num}:
    image: confluentinc/${CPIMAGE}:$VERSION
    container_name: kafka$num
    hostname: kafka$num
    networks:
      - confluent
    ports:
      - ${port}:${port}
EOF
    if [ $JMX -gt 0 ]; then
	cat << EOF
      - ${JMX}:${JMX}
EOF
    fi
    cat << EOF
    volumes:
      - kafka${num}-data:/var/lib/kafka/data
    environment:
      KAFKA_BROKER_ID: ${num}
      KAFKA_ZOOKEEPER_CONNECT: $ZKLIST
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,LOCALHOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka${num}:9092,LOCALHOST://localhost:${port}
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_DELETE_TOPIC_ENABLE: 'true'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: ${REPL}
      KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: '$METRICS'
EOF
    if [ $JMX -gt 0 ]; then
	cat << EOF
      KAFKA_JMX_OPTS: '-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=kafka${CL}${RK}$i -Dcom.sun.management.jmxremote.rmi.port=${JMX}'
      JMX_PORT: ${JMX}
EOF
    fi
    if [ $RACKS -gt 0 ]; then
	cat <<EOF
      KAFKA_BROKER_RACK: rack${RK}
EOF
    fi
}

components () {
    local CL=$1

    i=""
    p=$((9 - $CL))
    if [ $CLUSTERS -gt 1 ]; then
	i=$CL
    fi
    
    cat <<EOF

  schema-registry${i}:
    image: confluentinc/cp-schema-registry:$VERSION
    container_name: schema-registry${i}
    ports:
      - 1${p}081:${p}081
    networks:
      - confluent
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL: $ZKLIST
      SCHEMA_REGISTRY_LISTENERS: http://schema-registry:${p}081

  connect${i}:
    image: confluentinc/${KCIMAGE}:$VERSION
    container_name: connect${i}
    hostname: connect${i}
    ports:
      - 1${p}083:${p}083
    volumes:
      - ./connect${i}-data:/data
    networks:
      - confluent
    environment:
      CONNECT_PRODUCER_INTERCEPTOR_CLASSES: io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor
      CONNECT_CONSUMER_INTERCEPTOR_CLASSES: io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor
      CONNECT_BOOTSTRAP_SERVERS: $BOOT
      CONNECT_REST_PORT: ${p}083
      CONNECT_GROUP_ID: 'connect'
      CONNECT_CONFIG_STORAGE_TOPIC: 'connect-config'
      CONNECT_OFFSET_STORAGE_TOPIC: 'connect-offsets'
      CONNECT_STATUS_STORAGE_TOPIC: 'connect-status'
      CONNECT_REPLICATION_FACTOR: ${REPL}
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: ${REPL}
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: ${REPL}
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: ${REPL}
      CONNECT_KEY_CONVERTER: 'io.confluent.connect.avro.AvroConverter'
      CONNECT_VALUE_CONVERTER: 'io.confluent.connect.avro.AvroConverter'
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schema-registry:${p}081'
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schema-registry:${p}081'
      CONNECT_INTERNAL_KEY_CONVERTER: 'org.apache.kafka.connect.json.JsonConverter'
      CONNECT_INTERNAL_VALUE_CONVERTER: 'org.apache.kafka.connect.json.JsonConverter'
      CONNECT_REST_ADVERTISED_HOST_NAME: 'connect${i}'
      CONNECT_LOG4J_ROOT_LOGLEVEL: INFO
      CONNECT_LOG4J_LOGGERS: org.reflections=ERROR
      CONNECT_PLUGIN_PATH: /usr/share/java
      CONNECT_REST_HOST_NAME: 'connect${i}'

  rest-proxy${i}:
    image: confluentinc/cp-kafka-rest:$VERSION
    container_name: rest-proxy${i}
    ports:
      - 1${p}082:${p}082
    networks:
      - confluent
    environment:
      KAFKA_REST_HOST_NAME: rest-proxy
      KAFKA_REST_BOOTSTRAP_SERVERS: $BOOT
      KAFKA_REST_LISTENERS: 'http://0.0.0.0:${p}082'
      KAFKA_REST_SCHEMA_REGISTRY_URL: 'http://schema-registry:${p}081'
EOF
}

ksql () {
    local i=$1
    cat <<EOF

  ksql-server${i}:
    image: confluentinc/cp-ksql-server:$VERSION
    container_name: ksql-server${i}
    ports:
      - 1${i}088:8088
    networks:
      - confluent
    environment:
      KSQL_CONFIG_DIR: '/etc/ksql'
      KSQL_LOG4J_OPTS: '-Dlog4j.configuration=file:/etc/ksql/log4j.properties'
      KSQL_BOOTSTRAP_SERVERS: $BOOT
      KSQL_HOST_NAME: ksql-server${i}
      KSQL_APPLICATION_ID: 'etl-demo'
      KSQL_LISTENERS: 'http://ksql-server${i}:8088'
      KSQL_CACHE_MAX_BYTES_BUFFERING: 0
      KSQL_KSQL_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'
      KSQL_PRODUCER_INTERCEPTOR_CLASSES: io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor
      KSQL_CONSUMER_INTERCEPTOR_CLASSES: io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor
      KSQL_KSQL_SERVER_UI_ENABLED: 'false'
EOF
    if [ $i -eq 1 ]; then
	cat <<EOF

  ksql-cli:
    image: confluentinc/cp-ksql-cli:$VERSION
    container_name: ksql-cli
    networks:
      - confluent
    entrypoint: /bin/sh
    tty: true
EOF
    fi
}

ksqldb () {
    local i=$1
    cat <<EOF	    

  ksql-server${i}:
    image: confluentinc/cp-ksqldb-server:$VERSION
    container_name: ksql-server${i}
    ports:
      - 1${i}088:8088
    networks:
      - confluent
    environment:
      KSQL_CONFIG_DIR: '/etc/ksqldb'
      KSQL_LOG4J_OPTS: '-Dlog4j.configuration=file:/etc/ksqldb/log4j.properties'
      KSQL_BOOTSTRAP_SERVERS: $BOOT
      KSQL_HOST_NAME: ksql-server${i}
      KSQL_APPLICATION_ID: 'etl-demo'
      KSQL_LISTENERS: 'http://ksql-server${i}:8088'
      KSQL_CACHE_MAX_BYTES_BUFFERING: 0
      KSQL_KSQL_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'
      KSQL_PRODUCER_INTERCEPTOR_CLASSES: io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor
      KSQL_CONSUMER_INTERCEPTOR_CLASSES: io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor
      KSQL_KSQL_SERVER_UI_ENABLED: 'false'
EOF
    if [ $i -eq 1 ]; then
	cat <<EOF

  ksql-cli:
    image: confluentinc/cp-ksqldb-cli:$VERSION
    container_name: ksql-cli
    networks:
      - confluent
    entrypoint: /bin/sh
    tty: true
EOF
    fi
}

ksqlDB () {
    local i=$1
    cat <<EOF

  ksql-server${i}:
    image: confluentinc/ksqldb-server:latest
    hostname: ksql-server${i}
    container_name: ksql-server${i}
    ports:
      - 1${i}088:8088
    networks:
      - confluent
    environment:
      KSQL_LISTENERS: http://ksql-server${i}:8088
      KSQL_BOOTSTRAP_SERVERS: $BOOT
      KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: 'true'
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: 'true'
      KSQL_APPLICATION_ID: 'etl-demo'
      KSQL_KSQL_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'
EOF
    if [ $i -eq 1 ]; then
	cat <<EOF

  ksql-cli:
    image: confluentinc/ksqldb-cli:latest
    container_name: ksql-cli
    networks:
      - confluent
    entrypoint: /bin/sh
    tty: true
EOF
    fi
}

controlCenter() {
    cat <<EOF

  control-center:
    image: confluentinc/cp-enterprise-control-center:$VERSION
    container_name: control-center
    restart: always
    networks:
      - confluent
    ports:
      - 19021:9021
    environment:
      CONTROL_CENTER_BOOTSTRAP_SERVERS: $METRICS
EOF
    if [ $CLUSTERS -gt 1 ]; then
	i=1
	for b in $C3CL; do
	    cat <<EOF
      CONTROL_CENTER_KAFKA_CLUSTER${i}_BOOTSTRAP_SERVERS: $b
EOF
	    i=$(($i+1))
	done
    fi

   cat <<EOF
      CONTROL_CENTER_ZOOKEEPER_CONNECT: $C3ZK
      CONTROL_CENTER_REPLICATION_FACTOR: ${REPL}
      CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_REPLICATION: ${REPL}
      CONTROL_CENTER_INTERNAL_TOPICS_REPLICATION: ${REPL}
      CONTROL_CENTER_COMMAND_TOPIC_REPLICATION: ${REPL}
      CONTROL_CENTER_METRICS_TOPIC_REPLICATION: ${REPL}
      CONTROL_CENTER_STREAMS_NUM_STREAM_THREADS: 3
      CONTROL_CENTER_STREAMS_CONSUMER_REQUEST_TIMEOUT_MS: '960032'
      CONTROL_CENTER_CONNECT_CLUSTER: 'connect:8083'
      CONTROL_CENTER_KSQL_URL: 'http://ksql-server1:8088'
      CONTROL_CENTER_KSQL_DEFAULT_URL: 'http://ksql-server1:8088'
      CONTROL_CENTER_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'
EOF
}

volumes () {
    cat <<EOF

volumes:
EOF

    for i in $(seq 1 $ZK); do
	cat <<EOF
  zk${i}-data:
  zk${i}-log:
EOF
    done

    for c in $(seq 1 $CLUSTERS); do
	for i in $(seq 1 $AK); do
	    r=0
	    b=$i
	    if [ $RACKS -gt 0 ]; then
		r=$((($i - 1) % $RACKS + 1))
		b=$((($i - 1) / $RACKS + 1))
	    fi
	    cat <<EOF
  kafka${c}${r}${b}-data:
EOF
	done
    done

    cat <<EOF
networks:
  confluent:
EOF
}

#
# Parse arguments
#

ARGS="$@"

while getopts ":b:c:dD:hjkoOr:v:zZ:" o; do
    case "${o}" in
        b)
            AK=${OPTARG}
	    if [[ $AK -lt 1 ]]; then
		echo "Invalid number of brokers: $AK" 1>&2; exit 2;
	    fi
            ;;
	c)
            CLUSTERS=${OPTARG}
	    if [[ ( $CLUSTERS -lt 0 ) || ( $CLUSTERS -gt 9 ) ]]; then
		echo "Invalid number of clusters: $CLUSTERS" 1>&2; exit 2;
	    fi
	    ;;
	d)
	    KSQLDB=true
	    ;;
	D)
	    KSQLSRVRS=${OPTARG}
	    if [[ ( $KSQLSRVRS -lt 1 ) || ( $KSQLSRVRS -gt 9 ) ]]; then
		echo "Invalid number of ksql-server instances: $KSQLSRVRS" \
		     1>&2; exit 2;
	    fi
	    ;;
	j)
	    JMX_PORTS=true
	    ;;
	k)
	    KAFKA_ONLY=true
	    ;;
	o)
	    OBSERVE=false
	    ;;
	O)
	    OBSERVE=true
	    ;;
	r)
	    RACKS=${OPTARG}
	    if [[ ( $RACKS -lt 0 ) || ( $RACKS -gt 9 ) ]]; then
		echo "Invalid number of racks: $RACKS" 1>&2; exit 2;
	    fi
	    ;;
        v)
            VERSION=${OPTARG}
            ;;
	z)
	    ZK=3
	    ;;
	Z)
	    ZK=${OPTARG}
	    if [[ ( $ZK -lt 1 ) || ( $ZK -gt 9 ) ]]; then
		echo "Invalid number of zookeepers: $ZK" 1>&2; exit 2;
	    fi
	    ;;
        *)
            usage
            ;;
    esac
done
shift $((OPTIND-1))

#
# Validate and set global variables
#

if [[ $VERSION =~ ^[0-9].[0-9].[0-9]$ ]]; then
    VERINT=${VERSION//./}
else
    echo "Invalid version: $VERSION" 1>&2; exit 2;
fi

if [[ $RACKS -lt 1 ]]; then
    if [[ $AK -gt 9 ]]; then
	echo "Too many brokers for 0 racks: $AK" 1>&2; exit 2;
    fi
elif [[ $AK -gt $((9 * $RACKS)) ]]; then
    echo "Too many brokers for $RACKS racks: $AK" 1>&2; exit 2;
fi

if [ $OBSERVE = "null" ]; then
    if [ $KAFKA_ONLY = true ]; then
	OBSERVE=false
    else
	OBSERVE=true
    fi
fi

#
# call component functions
#

header

ZKNODES=""
ZKCONNECT="zk1:2181"

if [ $ZK -gt 1 ]; then
    ZKNODES=zk1:2888:3888  
    for i in $(seq 2 $ZK); do
	ZKNODES="${ZKNODES};zk${i}:2888:3888"
	ZKCONNECT="$ZKCONNECT,zk${i}:2181"
    done
fi

for i in $(seq 1 $ZK); do
    zookeeper "$i" "$ZKNODES"
done

REPL=3;
if [ $AK -lt 3 ]; then
    REPL=$AK
fi

#
# Per cluster components
#

for c in $(seq 1 $CLUSTERS); do
    ZKLIST=$ZKCONNECT

    if [ $CLUSTERS -gt 1 ]; then
	ZKLIST="${ZKLIST}/cluster$c"
    fi

    BOOT=""
    for i in $(seq 1 $REPL); do
	r=0
	b=$i
	if [ $RACKS -gt 0 ]; then
	    r=$((($i - 1) % $RACKS + 1))
	    b=$((($i - 1) / $RACKS + 1))
	fi
	if [ $i -eq 1 ]; then
	    BOOT="kafka${c}${r}${b}:9092"
	else
	    BOOT="${BOOT},kafka${c}${r}${b}:9092"
	fi
    done

    if [ $c -eq 1 ]; then
	C3ZK=$ZKLIST
	METRICS=$BOOT
	C3CL="$BOOT"
    else
	C3CL="$C3CL $BOOT"
    fi

    for i in $(seq 1 $AK); do
	r=0
	b=$i
	j=0

	if [ $RACKS -gt 0 ]; then
	    r=$((($i - 1) % $RACKS + 1))
	    b=$((($i - 1) / $RACKS + 1))
	fi
	if [[ ( $JMX_PORTS = true ) && ( $c -eq 1 ) && ( $i -le 9 ) ]]; then
	    j="999${i}"
	fi
	echo "CLUSTER $c RACK $r BROKER $b kafka$c$r$b" 1>&2

	broker "$c" "$r" "$b" "$j"

    done
    if [ $KAFKA_ONLY = false ]; then
	components "$c"
    fi
done

#
# Currently, KSQL is only configured for cluster 1
#

for i in $(seq 1 $KSQLSRVRS); do
    if [ $KAFKA_ONLY = false ]; then
	if [ $KSQLDB = true ]; then
	    ksqlDB "$i"
	    echo "ksqlDB $i ksql-server${i}" 1>&2
	elif [ $VERINT -ge 550 ]; then
	    ksqldb "$i"
	    echo "ksqldb $i ksql-server${i}" 1>&2
	elif [ $VERINT -ge 412 ]; then
	    ksql "$i"
	    echo "ksql $i ksql-server${i}" 1>&2
	fi
    fi
done

if [ $OBSERVE = true ]; then
    controlCenter
fi

volumes

exit 0
